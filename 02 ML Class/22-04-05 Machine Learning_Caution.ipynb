{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37e46a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9490451793199813\n",
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification의 대표적인 2개의 예제(위스콘신 유방암 데이터, Titanic)를 구현해보자\n",
    "# Binary Classification - 위스콘신 유방암 데이터 by Sklearn\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score # cross validation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from scipy import stats\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "# print(type(cancer))\n",
    "# <class 'sklearn.utils.Bunch'>. Sklearn이 데이터를 표현하기 위해 사용하는 자료구조. Python의 Dict와 유사함\n",
    "\n",
    "# print(cancer) # data이 독립변수, target이 종속변수\n",
    "# print(cancer.data.shape, cancer.target.shape) # (569, 30) (569,)\n",
    "\n",
    "# print(np.unique(cancer.target, return_counts=True)) # return_counts=True 값이 몇 개가 있는지\n",
    "# (array([0, 1]), array([212, 357], dtype=int64))\n",
    "\n",
    "# print(cancer.DESCR) # 유방암 데이터에 대한 상세 내용\n",
    "# Missing Attribute Values: None 결측치 없음\n",
    "# Class Distribution: 212 - Malignant(악성), 357 - Benign(정상)\n",
    "\n",
    "# Data Set\n",
    "x_data = cancer.data\n",
    "t_data = cancer.target\n",
    "\n",
    "# print(type(x_data), x_data.shape) # <class 'numpy.ndarray'> (569, 30)\n",
    "# print(type(t_data), t_data.shape) # <class 'numpy.ndarray'> (569,)\n",
    "\n",
    "# Hold-out Validation을 위해, Train과 Validation Data Set으로 분리.default는 75% : 25%\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(x_data, t_data, test_size=0.2, random_state=2, stratify=t_data) # stratify는 class의 개수를 맞춰줌\n",
    "# print(train_x_data.shape, train_t_data.shape) # (455, 30) (455,)\n",
    "# print(np.unique(train_t_data, return_counts=True)) # (array([0, 1]), array([170, 285], dtype=int64))\n",
    "\n",
    "# Model 생성\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "# K-Flod Cross Validation\n",
    "test_score = cross_val_score(model, x_data, t_data, scoring='accuracy', cv=5) # scoring은 metric 종류, cv은 몇 번 검증할지\n",
    "# print(test_score)\n",
    "print(test_score.mean()) # 0.9490451793199813%\n",
    "\n",
    "# Hold-out Validation\n",
    "model.fit(train_x_data, train_t_data)\n",
    "test_score = model.score(test_x_data, test_t_data)\n",
    "print(test_score) # 0.956140350877193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50eeb381",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value : 703.2249145507812\n",
      "loss value : 0.799042820930481\n",
      "loss value : 0.5356259942054749\n",
      "loss value : 0.4693799614906311\n",
      "loss value : 0.45146843791007996\n",
      "loss value : 0.4825952351093292\n",
      "loss value : 0.5068585872650146\n",
      "loss value : 0.5115243196487427\n",
      "loss value : 0.5085011124610901\n",
      "loss value : 0.502677321434021\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification - 위스콘신 유방암 데이터 by Tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(shape=[None,30], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias\n",
    "W = tf.Variable(tf.random.normal([30,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis, model, predict model, Logistic Regression Model\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cross entropy(loss func)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 반복 학습\n",
    "# 전체 데이터를 이용해서 1번 학습하는 것을 1 epoch이라 함\n",
    "for step in range(100000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X: train_x_data, T: train_t_data.reshape(-1,1)})\n",
    "    \n",
    "    if step % 10000 == 0:\n",
    "        print('loss value : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2421719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9122806787490845\n"
     ]
    }
   ],
   "source": [
    "# Accuracy 측정\n",
    "\n",
    "# validation data(test_x_data, test_t_data)를 이용해서 정확도를 측정\n",
    "predict = tf.cast(H >= 0.5, dtype=tf.float32) # True -> 1.0, False -> 0.0\n",
    "correct = tf.equal(predict, T) # equal은 predict와 T가 같은지 비교. boolean으로 나옮(True, False, Flase, True...)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32)) # correct를 실수로 바꿔서 평균을 구함(cross entropy)\n",
    "\n",
    "accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data, T: test_t_data.reshape(-1,1)})\n",
    "print('Accuracy : {}'.format(accuracy_val)) # Accuracy : 0.9122806787490845"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF15] *",
   "language": "python",
   "name": "conda-env-machine_TF15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
