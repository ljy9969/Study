{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06000d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression의 Accuracy : 0.9851666666666666\n",
      "KNN의 Accuracy : 0.9985\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + KNN - BMI data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier # 분류기\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3)\n",
    "\n",
    "# Data Split\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(df[['height', 'weight']], df['label'], test_size=0.3, random_state=1, stratify=df['label'])\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(norm_train_x_data, train_t_data)\n",
    "\n",
    "acc = model.score(norm_test_x_data, test_t_data)\n",
    "print('Logistic Regression의 Accuracy : {}'.format(acc)) # 0.9851666666666666\n",
    "\n",
    "# KNN으로 구현\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3) # 동심원을 그려서 주변의 값 3개를 가져와라\n",
    "knn_classifier.fit(norm_train_x_data, train_t_data)\n",
    "acc = knn_classifier.score(norm_test_x_data, test_t_data)\n",
    "print('KNN의 Accuracy : {}'.format(acc)) # 0.9985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05b437f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? ㅛ\n",
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9bcf39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression + KNN by Tensorflow 2.x - Ozone data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KNeighborsRegressor # 연속적인 숫자값을 예측\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/ozone.csv')\n",
    "\n",
    "x_data = df[['Solar.R', 'Wind', 'Temp']] # 2차원 DataFrame\n",
    "t_data = df['Ozone']\n",
    "\n",
    "# 1. 독립변수에 대한 결측치를 찾아서 중위값으로 보간(대체)\n",
    "for col in x_data.columns:\n",
    "    col_median = np.nanmedian(x_data[col])\n",
    "    x_data[col].loc[x_data[col].isnull()] = col_median\n",
    "    \n",
    "# 2. 독립변수의 이상치를 찾아 이상치를 제외한 나머지 값들의 평균으로 이상치를 대체\n",
    "zscore_threshold = 2.0\n",
    "\n",
    "for col in x_data.columns:\n",
    "    outlier = x_data[col][np.abs(stats.zscore(x_data[col])) > zscore_threshold]\n",
    "    col_mean = np.mean(x_data.loc[~x_data[col].isin(outlier),col])\n",
    "    x_data.loc[x_data[col].isin(outlier), col] = col_mean\n",
    "    \n",
    "# 3. 종속변수의 이상치를 찾아 이상치를 제외한 나머지 값들의 평균으로 이상치를 대체\n",
    "outlier = t_data[np.abs(stats.zscore(t_data)) > zscore_threshold]\n",
    "col_mean = np.mean(~t_data.isin(outlier))\n",
    "t_data[t_data.isin(outlier)] = col_mean\n",
    "\n",
    "# 4. 정규화 진행\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_t = MinMaxScaler()\n",
    "\n",
    "scaler_x.fit(x_data.values) # scaler는 2차원 ndarray로 사용해야 함\n",
    "scaler_t.fit(t_data.values.reshape(-1,1))\n",
    "\n",
    "norm_x_data = scaler_x.transform(x_data.values)\n",
    "norm_t_data = scaler_t.transform(t_data.values.reshape(-1,1)).ravel()\n",
    "\n",
    "# 5. 종속변수에 대한 결측치는 KNN을 이용해 impotation(보간)\n",
    "# 종속변수가 결측치가 아닌 독립&종속변수들을 추출(KNN 학습을 위해)\n",
    "norm_train_x_data = norm_x_data[~np.isnan(norm_t_data)]\n",
    "norm_train_t_data = norm_t_data[~np.isnan(norm_t_data)]\n",
    "\n",
    "# Model 생성\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=2)\n",
    "knn_regressor.fit(norm_train_x_data, norm_train_t_data)\n",
    "\n",
    "# 종속변수가 결측치인 독립변수들을 입력으로 넣어서 값을 예측\n",
    "knn_predict = knn_regressor.predict(norm_x_data[np.isnan(norm_t_data)])\n",
    "norm_t_data[np.isnan(norm_t_data)] = knn_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1fa473c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn 예측값 : [[36.93077619]]\n",
      "Tensorflow 예측값 : [[36.760612]]\n"
     ]
    }
   ],
   "source": [
    "# 최종 데이터는 norm_x_data, norm_t_data\n",
    "# Sklearn과 Tensorflow 2.x로 구현해보자\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "test_data = np.array([[330, 15, 80]]) # 태양광, 바람, 온도\n",
    "\n",
    "# Sklearn 구현\n",
    "model = LinearRegression()\n",
    "model.fit(norm_x_data, norm_t_data)\n",
    "result = model.predict(scaler_x.transform(test_data))\n",
    "print('sklearn 예측값 : {}'.format(scaler_t.inverse_transform(result.reshape(-1,1)))) # 36.93077619\n",
    "\n",
    "# Tensorflow 2.x 구현\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(3,))) # input layer. 독립변수 3개 튜플로 입력\n",
    "keras_model.add(Dense(units=1, activation='linear')) # output layer. class와 logistic의 개수는 1\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='mse')\n",
    "\n",
    "keras_model.fit(norm_x_data, norm_t_data, epochs=5000, verbose=0)\n",
    "\n",
    "result = keras_model.predict(scaler_x.transform(test_data))\n",
    "print('Tensorflow 예측값 : {}'.format(scaler_t.inverse_transform(result.reshape(-1,1)))) # 36.760612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b327afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16bfe57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Embarked  Family\n",
       "0         0       3    0    0         0       1\n",
       "1         1       1    1    1         1       1\n",
       "2         1       3    1    1         0       0\n",
       "3         1       1    1    1         0       1\n",
       "4         0       3    0    1         0       0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression(Binary Classification) by Sklearn / Tensorflow 2.x - Titanic\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 이상치는 실제 데이터이기 때문에 처리하지 않고 결측치만 처리할 예정\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/titanic/train.csv')\n",
    "\n",
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'], axis=1, inplace=False)\n",
    "\n",
    "df['Family'] = df['SibSp'] + df['Parch']\n",
    "df = df.drop(['SibSp', 'Parch'], axis=1, inplace=False)\n",
    "\n",
    "# 결측치 처리\n",
    "df['Embarked'] = df['Embarked'].fillna('Q')\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# 문자로 되어 있는 값을 숫자로 변경\n",
    "gender_string = {'male': 0, 'female': 1}\n",
    "df['Sex'] = df['Sex'].map(gender_string)\n",
    "\n",
    "embarked_string = {'S': 0, 'C': 1, 'Q': 2}\n",
    "df['Embarked'] = df['Embarked'].map(embarked_string)\n",
    "\n",
    "def age_category(age): # \n",
    "    if ((age >= 0) & (age < 25)):\n",
    "        return 0\n",
    "    elif ((age >= 25) & (age < 50)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "df['Age'] = df['Age'].map(age_category)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "03020d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn 정확도 : 0.7873134328358209\n"
     ]
    }
   ],
   "source": [
    "# Data Split\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(df.drop('Survived', axis=1, inplace=False), df['Survived'], test_size=0.3, random_state=1, stratify=df['Survived'])\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)\n",
    "\n",
    "# Sklearn 구현\n",
    "model = LogisticRegression()\n",
    "model.fit(norm_train_x_data, train_t_data)\n",
    "sklearn_result = model.score(norm_test_x_data, test_t_data)\n",
    "print('Sklearn 정확도 : {}'.format(sklearn_result)) # 0.7873134328358209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8ec112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 779us/step - loss: 0.4663 - accuracy: 0.7910\n",
      "Tensorflow 정확도 : [0.4663046896457672, 0.7910447716712952]\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow 2.x 구현\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(5,))) # input layer\n",
    "keras_model.add(Dense(units=1, activation='sigmoid')) # output layer\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "keras_model.fit(norm_train_x_data, train_t_data, epochs=1000, verbose=0)\n",
    "\n",
    "keras_result = keras_model.evaluate(norm_test_x_data, test_t_data)\n",
    "print('Tensorflow 정확도 : {}'.format(keras_result)) # 0.7910447716712952"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2] *",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
