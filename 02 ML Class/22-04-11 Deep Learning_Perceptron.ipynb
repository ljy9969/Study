{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5851a95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value : 0.7378681898117065\n",
      "loss value : 0.694304347038269\n",
      "loss value : 0.6932241916656494\n",
      "loss value : 0.6931537389755249\n",
      "loss value : 0.6931477785110474\n",
      "loss value : 0.6931473016738892\n",
      "loss value : 0.6931471824645996\n",
      "loss value : 0.6931471824645996\n",
      "loss value : 0.6931471824645996\n",
      "loss value : 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression으로 GATE 연산을 학습할 수 있는지 확인해보자\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Training Data Set\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float64)\n",
    "\n",
    "# # AND GATE 연산에 대한 t_data\n",
    "# t_data = np.array([0, 0, 0, 1], dtype=np.float32) # [[0.][0.][0.][1.]]\n",
    "\n",
    "# # OR GATE 연산에 대한 t_data\n",
    "# t_data = np.array([0, 1, 1, 1], dtype=np.float64) # [[0.][1.][1.][1.]]\n",
    "\n",
    "# XOR GATE 연산에 대한 t_data. exclusive OR\n",
    "t_data = np.array([0, 1, 1, 0], dtype=np.float64) # accuracy 0.75. loss도 떨어지지 않는다\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias\n",
    "W = tf.Variable(tf.random.normal([2,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis, model, predict model, Logistic Regression Model\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cross entropy(loss func)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 반복 학습\n",
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X:x_data, T:t_data.reshape(-1,1)})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss value : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b27d2c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.50      0.40         2\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.25         4\n",
      "   macro avg       0.17      0.25      0.20         4\n",
      "weighted avg       0.17      0.25      0.20         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation(모델평가)\n",
    "predict = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "predict_val = sess.run(predict, feed_dict={X:x_data})\n",
    "print(predict_val)\n",
    "\n",
    "print(classification_report(t_data, predict_val.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21eed14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value : 0.8213931322097778\n",
      "loss value : 0.6699194312095642\n",
      "loss value : 0.6421100497245789\n",
      "loss value : 0.5833636522293091\n",
      "loss value : 0.4641253650188446\n",
      "loss value : 0.2832849323749542\n",
      "loss value : 0.1470194160938263\n",
      "loss value : 0.08339200913906097\n",
      "loss value : 0.05397495627403259\n",
      "loss value : 0.03853011131286621\n"
     ]
    }
   ],
   "source": [
    "# DNN으로 GATE 연산(XOR)을 학습할 수 있는지 확인해보자\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Training Data Set\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float64)\n",
    "\n",
    "# XOR GATE 연산에 대한 t_data. exclusive OR\n",
    "t_data = np.array([0, 1, 1, 0], dtype=np.float64) # [[0.][1.][1.][0.]]. accuracy 1.00\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias\n",
    "W2 = tf.Variable(tf.random.normal([2,10])) # Input Layer\n",
    "b2 = tf.Variable(tf.random.normal([10]))\n",
    "layer2 = tf.sigmoid(tf.matmul(X,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal([10,6])) # Hidden Layer\n",
    "b3 = tf.Variable(tf.random.normal([6]))\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2,W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random.normal([6,1])) # Hidden Layer\n",
    "b4 = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis, model, predict model, Logistic Regression Model\n",
    "logit = tf.matmul(layer3,W4) + b4 # Output Layer\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cross entropy(loss func)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 반복 학습\n",
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X:x_data, T:t_data.reshape(-1,1)})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss value : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a05a2b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "         1.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation(모델평가)\n",
    "predict = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "predict_val = sess.run(predict, feed_dict={X:x_data})\n",
    "print(predict_val)\n",
    "\n",
    "print(classification_report(t_data, predict_val.ravel())) # accuracy 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50687053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ec5f062730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow 2.x 버전으로 구현\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Training Data Set\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float64)\n",
    "\n",
    "# XOR GATE 연산에 대한 t_data. exclusive OR\n",
    "t_data = np.array([0, 1, 1, 0], dtype=np.float64)\n",
    "\n",
    "# Tensorflow 구현\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(2,))) # input layer\n",
    "model.add(Dense(units=128, activation='sigmoid')) # 첫 번째 hidden layer. W 잡아주지 않음\n",
    "model.add(Dense(units=32, activation='sigmoid')) # 두 번째 hidden layer\n",
    "model.add(Dense(units=16, activation='sigmoid')) # 두 번째 hidden layer\n",
    "model.add(Dense(units=1, activation='sigmoid')) # output layer\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=1e-2), loss='binary_crossentropy')\n",
    "\n",
    "model.fit(x_data, t_data.reshape(-1,1), epochs=30000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d109ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.50      0.50         2\n",
      "         1.0       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.50      0.50      0.50         4\n",
      "weighted avg       0.50      0.50      0.50         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation(모델평가)\n",
    "predict_val = model.predict(x_data)\n",
    "predict_val = (tf.cast(predict_val > 0.5, dtype=tf.float32)).numpy().ravel()\n",
    "\n",
    "print(classification_report(t_data, predict_val)) # accuracy 0.50\n",
    "# 파라미터 조절을 더 해야 해요!!!\n",
    "# 정상적으로 학습이 진행되어야 해요!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2]",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
