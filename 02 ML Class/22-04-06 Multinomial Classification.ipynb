{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e54aaa4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model의 정확도 : 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification - 위스콘신 유방암 데이터 by Gradient Descent Classifier\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Raw Data Set Loading\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Data Set\n",
    "x_data = cancer.data # 2차원 ndarray 독립변수(feature)\n",
    "t_data = cancer.target # 1차원 ndarray 종속변수(label)\n",
    "\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(x_data, t_data, test_size=0.3, random_state=2, stratify=t_data) # stratify=t_data는 데이터가 편향되는 것을 방지함\n",
    "\n",
    "# Model 생성\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "# Model 학습\n",
    "model.fit(train_x_data, train_t_data)\n",
    "\n",
    "# Accuracy로 Model 평가\n",
    "test_score = model.score(test_x_data, test_t_data)\n",
    "\n",
    "print('Logistic Regression Model의 정확도 : {}'.format(test_score)) # 0.9473684210526315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bef370c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier의 정확도 : 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification - 위스콘신 유방암 데이터 by SGD Classifier Ver. 1(정규화 안 함)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Raw Data Set Loading\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Data Set\n",
    "x_data = cancer.data\n",
    "t_data = cancer.target\n",
    "\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(x_data, t_data, test_size=0.3, random_state=2, stratify=t_data)\n",
    "\n",
    "# Model 생성\n",
    "sgd = linear_model.SGDClassifier(loss='log', # loss='log'는 Logistic Regression을 이용해 Binary Classification 하겠다.\n",
    "                                tol=1e-5,    # log loss가 1e-5이면 반복을 멈춤\n",
    "                                random_state=2)\n",
    "\n",
    "# Model 학습\n",
    "sgd.fit(train_x_data, train_t_data)\n",
    "\n",
    "# Accuracy로 Model 평가\n",
    "test_score = sgd.score(test_x_data, test_t_data)\n",
    "\n",
    "print('SGD Classifier의 정확도 : {}'.format(test_score)) # 0.8947368421052632. 정규화를 안 했기 때문에 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e96bcd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화를 이용한 SGD Classifier의 정확도 : 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification - 위스콘신 유방암 데이터 by SGD Classifier Ver. 2(정규화함)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Raw Data Set Loading\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Data Set\n",
    "x_data = cancer.data\n",
    "t_data = cancer.target\n",
    "\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(x_data, t_data, test_size=0.3, random_state=2, stratify=t_data)\n",
    "\n",
    "# Data 정규화\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "# Model 생성\n",
    "sgd = linear_model.SGDClassifier(loss='log', # loss='log'는 Logistic Regression을 이용해 Binary Classification 하겠다.\n",
    "                                tol=1e-5,    # log loss가 1e-5이면 반복을 멈춤\n",
    "                                random_state=2)\n",
    "\n",
    "# Model 학습\n",
    "sgd.fit(scaler.transform(train_x_data), train_t_data)\n",
    "\n",
    "# Accuracy로 Model 평가\n",
    "test_score = sgd.score(scaler.transform(test_x_data), test_t_data)\n",
    "\n",
    "print('정규화를 이용한 SGD Classifier의 정확도 : {}'.format(test_score)) # 0.9649122807017544. 정규화를 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1132d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화를 이용한 SGD Classifier의 정확도 : 0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification - 위스콘신 유방암 데이터 by SGD Classifier Ver. 3(정규화 + L2 Regularization <- Over-fitting(과대 적합) 방지)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Raw Data Set Loading\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Data Set\n",
    "x_data = cancer.data\n",
    "t_data = cancer.target\n",
    "\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(x_data, t_data, test_size=0.3, random_state=2, stratify=t_data)\n",
    "\n",
    "# Data 정규화\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "# Model 생성\n",
    "sgd = linear_model.SGDClassifier(loss='log', # loss='log'는 Logistic Regression을 이용해 Binary Classification 하겠다.\n",
    "                                tol=1e-5,    # log loss가 1e-5이면 반복을 멈춤\n",
    "                                random_state=2, # Random Seed\n",
    "                                penalty='l2', # L2 - Ridge Regression로 규제 적용\n",
    "                                alpha=0.001) # 규제 강도\n",
    "\n",
    "# Model 학습\n",
    "sgd.fit(scaler.transform(train_x_data), train_t_data)\n",
    "\n",
    "# Accuracy로 Model 평가\n",
    "test_score = sgd.score(scaler.transform(test_x_data), test_t_data)\n",
    "\n",
    "print('정규화를 이용한 SGD Classifier의 정확도 : {}'.format(test_score)) # 0.9707602339181286. 정규화 + L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0fee2a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2a525380",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  height  weight\n",
       "0      1     188      71\n",
       "1      2     161      68\n",
       "2      0     178      52\n",
       "3      2     136      63\n",
       "4      1     145      52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   label   20000 non-null  int64\n",
      " 1   height  20000 non-null  int64\n",
      " 2   weight  20000 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 468.9 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multinomial Classification - BMI 데이터 by Sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler # 결측치가 없기 때문에 정규화에 MinMaxScaler 사용\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3) # skiprows는 주석이 달려있는 상위 3행을 제외해라\n",
    "# label 0: thin\n",
    "# label 1: normal\n",
    "# label 2: fat\n",
    "\n",
    "display(df.head()); print(df.shape); display(df.info()) # (20000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7ef13983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# print(df.isnull().sum()) # None\n",
    "\n",
    "zscore_threshold = 2.0 # Z-score로 이상치 처리\n",
    "(np.abs(stats.zscore(df['height'])) > zscore_threshold).sum() # None\n",
    "(np.abs(stats.zscore(df['weight'])) > zscore_threshold).sum() # None\n",
    "\n",
    "#(array([0, 1, 2], dtype=int64), array([6470, 5857, 7673], dtype=int64))\n",
    "# np.unique(df['label'], return_counts=True) # class의 비율 확인\n",
    "\n",
    "# Train과 Validation Data Set으로 분리\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(df[['height', 'weight']], df['label'], test_size=0.3, random_state=1, stratify=df['label'])\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5cfeaa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn으로 구현한 Accuracy : 0.9845\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Model 생성 후 학습 및 평가\n",
    "model = linear_model.LogisticRegression(C=1000) # C 옵션(alpha 값)으로 L2 규제를 적용할 수 있음. alpha=0.001(1/1000)\n",
    "model.fit(norm_train_x_data, train_t_data)\n",
    "\n",
    "predict_val = model.predict(norm_test_x_data)\n",
    "acc = accuracy_score(predict_val, test_t_data)\n",
    "\n",
    "print('Sklearn으로 구현한 Accuracy : {}'.format(acc)) # 0.9851666666666666, 0.9845\n",
    "\n",
    "# Prediction\n",
    "result = model.predict(scaler.transform(np.array([[187, 81]]))) # 187, 81 -> 1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5c849085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value : 0.9441623687744141\n",
      "loss value : 0.16499893367290497\n",
      "loss value : 0.12282320111989975\n",
      "loss value : 0.10350026935338974\n",
      "loss value : 0.09194015711545944\n",
      "loss value : 0.08408293128013611\n",
      "loss value : 0.07831946760416031\n",
      "loss value : 0.07387088239192963\n",
      "loss value : 0.07030844688415527\n",
      "loss value : 0.06737658381462097\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Classification - BMI 데이터 by Tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sess = tf.Session() # Tensorflow의 기능을 이용해 인코딩을 하므로 node가 생성됨\n",
    "onehot_train_t_data = sess.run(tf.one_hot(train_t_data, depth=3)) # depth 옵션으로 class의 개수를 알려줘야 함\n",
    "onehot_test_t_data = sess.run(tf.one_hot(test_t_data, depth=3))\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32) # 독립변수(feature)의 개수\n",
    "T = tf.placeholder(shape=[None,3], dtype=tf.float32) # 원핫 인코딩! class의 개수이면서 Logistic의 개수\n",
    "\n",
    "# Weight, bias\n",
    "W = tf.Variable(tf.random.normal([2,3])) # 독립변수 2개, W 3개\n",
    "b = tf.Variable(tf.random.normal([3]))\n",
    "\n",
    "# Model, Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit) # Multinomial Classification의 Softmax\n",
    "\n",
    "# Cross Entropy(loss func)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=T))\n",
    "\n",
    "# Train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(loss)\n",
    "\n",
    "# Session 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 반복 학습\n",
    "# for step in range(10000):\n",
    "#     _, loss_val = sess.run([train, loss], feed_dict={X:norm_train_x_data, T:onehot_train_t_data})\n",
    "    \n",
    "#     if step % 1000 == 0:\n",
    "#         print('loss value : {}'.format(loss_val))\n",
    "\n",
    "# Memory Fault 나는 것을 방지하기 위해 데이터를 쪼개서 학습 -> batch 처리\n",
    "num_of_epoch = 1000 # 학습을 위한 전체 epoch 수\n",
    "num_of_batch = 100   # 한번에 학습할 데이터 양\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    total_batch = int(norm_train_x_data.shape[0] / num_of_batch) # 학습 데이터의 개수 / batch\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x = norm_train_x_data[i*num_of_batch:(i+1)*num_of_batch] # [0:100], [100:200] ~. 100개씩 Slicing\n",
    "        batch_y = onehot_train_t_data[i*num_of_batch:(i+1)*num_of_batch]\n",
    "        _, loss_val = sess.run([train, loss], feed_dict={X:batch_x, T:batch_y})\n",
    "        \n",
    "    if step % 100 == 0:\n",
    "        print('loss value : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2fbef8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9855\n"
     ]
    }
   ],
   "source": [
    "# 성능평가(Accuracy)\n",
    "result = sess.run(H, feed_dict={X:scaler.transform(np.array([[187, 81]]))})\n",
    "\n",
    "# print(result)       # [[4.761967e-05 9.079144e-01 9.203796e-02]]\n",
    "# print(result[0,1])  # 0.9079144\n",
    "# print(result.max()) # 중간의 0.9079144(1)가 가장 높은 확률\n",
    "# print(np.argmax(result, axis=1)) # [1].가장 큰 값의 index를 추출\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(T,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "result = sess.run(accuracy, feed_dict={X:norm_test_x_data, T:onehot_test_t_data})\n",
    "print(result) # 0.9855"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF15] *",
   "language": "python",
   "name": "conda-env-machine_TF15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
